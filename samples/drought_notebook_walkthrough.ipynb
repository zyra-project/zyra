{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Zyra Notebook: Drought Animation Walkthrough (draft)\n",
    "\n",
    "This walkthrough recreates the `samples/swarm/drought_animation.yaml` flow:\n",
    "\n",
    "- Sync the last year of weekly drought frames from NOAA FTP.\n",
    "- Scan frames metadata to identify cadence/missing timestamps.\n",
    "- Fill gaps with a basemap-backed placeholder set.\n",
    "- Compose an MP4 animation and write it locally.\n",
    "- Optional narration via `narrate swarm` with mock-safe provider selection.\n",
    "- Export pipeline/CLI equivalents for reproducibility.\n",
    "\n",
    "Prereqs: Pillow for `process pad-missing`, FFmpeg on `PATH` for `visualize compose-video`, and access to the packaged basemap `pkg:zyra.assets/images/earth_vegetation.jpg` (avoids external downloads).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "provider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM model: gemma3:12b\n",
      "LLM provider: ollama\n"
     ]
    }
   ],
   "source": [
    "# LLM provider (optional narration; mock-safe fallback)\n",
    "import os\n",
    "\n",
    "# Prefer Ollama; set base/model here if not already exported in the env\n",
    "os.environ.setdefault(\"ZYRA_LLM_PROVIDER\", \"ollama\")\n",
    "os.environ.setdefault(\"OLLAMA_BASE_URL\", \"http://host.docker.internal:11434\")\n",
    "os.environ.setdefault(\"LLM_MODEL\", \"gemma3:12b\")\n",
    "\n",
    "PROVIDER = os.environ.get(\"ZYRA_LLM_PROVIDER\", \"ollama\")\n",
    "AVAILABLE = {\"ollama\", \"openai\", \"google\", \"mock\"}\n",
    "if PROVIDER not in AVAILABLE:\n",
    "    PROVIDER = \"ollama\"\n",
    "\n",
    "\n",
    "def choose_provider() -> str:\n",
    "    has_openai = bool(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    has_google = bool(os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "    has_ollama = bool(os.environ.get(\"OLLAMA_BASE_URL\"))\n",
    "    if PROVIDER == \"openai\" and has_openai:\n",
    "        return \"openai\"\n",
    "    if PROVIDER == \"google\" and has_google:\n",
    "        return \"google\"\n",
    "    if PROVIDER == \"ollama\" and has_ollama:\n",
    "        return \"ollama\"\n",
    "    return \"mock\"\n",
    "\n",
    "\n",
    "LLM_PROVIDER = choose_provider()\n",
    "LLM_MODEL = os.environ.get(\"LLM_MODEL\")\n",
    "print(\"LLM model:\", LLM_MODEL)\n",
    "print(\"LLM provider:\", LLM_PROVIDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace root: /app/data\n",
      "Drought run dir: /app/data/drought_notebook\n"
     ]
    }
   ],
   "source": [
    "# Notebook session + workspace\n",
    "from pathlib import Path\n",
    "\n",
    "from zyra.notebook import create_session\n",
    "\n",
    "# Default workspace: ZYRA_NOTEBOOK_DIR -> /kaggle/working -> cwd\n",
    "os.environ[\"ZYRA_NOTEBOOK_DIR\"] = \"/app/data\"\n",
    "sess = create_session()\n",
    "WORKSPACE = sess.workspace()\n",
    "DROUGHT_DIR = WORKSPACE / \"drought_notebook\"\n",
    "DROUGHT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Workspace root:\", WORKSPACE)\n",
    "print(\"Drought run dir:\", DROUGHT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "paths",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw frames dir: /app/data/drought_notebook/frames_raw\n",
      "Padded frames dir: /app/data/drought_notebook/frames_padded\n"
     ]
    }
   ],
   "source": [
    "# Paths and cadence defaults\n",
    "FRAMES_RAW = DROUGHT_DIR / \"frames_raw\"\n",
    "FRAMES_PADDED = DROUGHT_DIR / \"frames_padded\"\n",
    "FRAMES_META = DROUGHT_DIR / \"frames_meta.json\"\n",
    "VIDEO_OUT = DROUGHT_DIR / \"drought_animation.mp4\"\n",
    "BASEMAP_REF = \"pkg:zyra.assets/images/earth_vegetation.jpg\"\n",
    "\n",
    "FTP_PATH = \"ftp://ftp.nnvl.noaa.gov/SOS/DroughtRisk_Weekly\"\n",
    "PATTERN = r\"^DroughtRisk_Weekly_[0-9]{8}\\.png$\"  # single-escaped dot\n",
    "CADENCE_SECONDS = 7 * 24 * 3600\n",
    "\n",
    "for folder in (FRAMES_RAW, FRAMES_PADDED):\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Raw frames dir:\", FRAMES_RAW)\n",
    "print(\"Padded frames dir:\", FRAMES_PADDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acquire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remote frames past year: 51\n",
      "Remote date span: 2024-12-05 to 2025-11-20\n",
      "Newest remote samples: ['DroughtRisk_Weekly_20251106.png', 'DroughtRisk_Weekly_20251113.png', 'DroughtRisk_Weekly_20251120.png']\n",
      "Synced frames from FTP -> /app/data/drought_notebook/frames_raw\n",
      "Local frames downloaded: 51\n",
      "Newest local files: ['DroughtRisk_Weekly_20251106.png', 'DroughtRisk_Weekly_20251113.png', 'DroughtRisk_Weekly_20251120.png']\n"
     ]
    }
   ],
   "source": [
    "# Acquire drought frames (FTP sync for the past year)\n",
    "import contextlib\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from zyra.connectors.backends import ftp as ftp_backend\n",
    "from zyra.utils.date_manager import DateManager\n",
    "\n",
    "\n",
    "def frame_count(path: Path) -> int:\n",
    "    return sum(1 for f in path.iterdir() if f.is_file())\n",
    "\n",
    "\n",
    "date_start, _ = DateManager().get_date_range_iso(\"P1Y\")\n",
    "remote_filtered = (\n",
    "    ftp_backend.list_files(\n",
    "        FTP_PATH,\n",
    "        pattern=PATTERN,\n",
    "        since=date_start.isoformat(),\n",
    "        date_format=\"%Y%m%d\",\n",
    "    )\n",
    "    or []\n",
    ")\n",
    "dates = []\n",
    "for name in remote_filtered:\n",
    "    m = re.search(r\"(\\d{8})\", name)\n",
    "    if m:\n",
    "        with contextlib.suppress(Exception):\n",
    "            dates.append(datetime.strptime(m.group(1), \"%Y%m%d\"))\n",
    "print(f\"Remote frames past year: {len(remote_filtered)}\")\n",
    "if dates:\n",
    "    print(\"Remote date span:\", min(dates).date(), \"to\", max(dates).date())\n",
    "if remote_filtered:\n",
    "    print(\"Newest remote samples:\", remote_filtered[-3:])\n",
    "\n",
    "try:\n",
    "    sess.acquire.ftp(\n",
    "        path=FTP_PATH,\n",
    "        sync_dir=str(FRAMES_RAW),\n",
    "        pattern=PATTERN,\n",
    "        since_period=\"P1Y\",\n",
    "        date_format=\"%Y%m%d\",\n",
    "    )\n",
    "    print(\"Synced frames from FTP ->\", FRAMES_RAW)\n",
    "except Exception as exc:\n",
    "    raise RuntimeError(f\"FTP sync failed: {exc}\") from exc\n",
    "\n",
    "ready = frame_count(FRAMES_RAW)\n",
    "print(f\"Local frames downloaded: {ready}\")\n",
    "if ready:\n",
    "    sample_local = sorted(FRAMES_RAW.iterdir())[-3:]\n",
    "    print(\"Newest local files:\", [p.name for p in sample_local])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gap-note",
   "metadata": {},
   "source": [
    "## Create a gap in the frames\n",
    "We'll delete a couple of frames to see how pad-missing backfills missing timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gap-delete",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted frames: ['DroughtRisk_Weekly_20250109.png', 'DroughtRisk_Weekly_20250522.png']\n",
      "Remaining frame count: 49\n"
     ]
    }
   ],
   "source": [
    "# Remove two frames to simulate missing data\n",
    "import random\n",
    "\n",
    "frames = sorted(p for p in FRAMES_RAW.iterdir() if p.is_file())\n",
    "if len(frames) < 2:\n",
    "    print(\"Not enough frames to delete; skipping gap simulation\")\n",
    "else:\n",
    "    to_delete = random.sample(frames, 2)\n",
    "    for fp in to_delete:\n",
    "        fp.unlink(missing_ok=True)\n",
    "    print(\"Deleted frames:\", [fp.name for fp in sorted(to_delete)])\n",
    "    print(\"Remaining frame count:\", sum(1 for f in FRAMES_RAW.iterdir() if f.is_file()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames meta: /app/data/drought_notebook/frames_meta.json\n",
      "Actual frames: 49 Missing: 2\n"
     ]
    }
   ],
   "source": [
    "# Scan frames metadata (cadence, missing timestamps)\n",
    "import json\n",
    "\n",
    "meta_result = sess.transform.scan_frames(\n",
    "    frames_dir=str(FRAMES_RAW),\n",
    "    pattern=PATTERN,\n",
    "    datetime_format=\"%Y%m%d\",\n",
    "    period_seconds=CADENCE_SECONDS,\n",
    "    output=str(FRAMES_META),\n",
    ")\n",
    "summary = json.loads(FRAMES_META.read_text()) if FRAMES_META.exists() else {}\n",
    "print(\"Frames meta:\", FRAMES_META)\n",
    "print(\n",
    "    \"Actual frames:\",\n",
    "    summary.get(\"frame_count_actual\"),\n",
    "    \"Missing:\",\n",
    "    summary.get(\"missing_count\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded frames dir: /app/data/drought_notebook/frames_padded\n",
      "Total frames after padding: 51\n"
     ]
    }
   ],
   "source": [
    "# Fill missing frames using basemap placeholders\n",
    "import shutil\n",
    "\n",
    "# Start padded dir fresh and seed it with existing frames\n",
    "if FRAMES_PADDED.exists():\n",
    "    shutil.rmtree(FRAMES_PADDED)\n",
    "FRAMES_PADDED.mkdir(parents=True, exist_ok=True)\n",
    "for src in FRAMES_RAW.iterdir():\n",
    "    if src.is_file():\n",
    "        shutil.copy2(src, FRAMES_PADDED / src.name)\n",
    "\n",
    "pad_result = sess.process.pad_missing(\n",
    "    frames_meta=str(FRAMES_META),\n",
    "    output_dir=str(FRAMES_PADDED),\n",
    "    fill_mode=\"basemap\",\n",
    "    basemap=BASEMAP_REF,\n",
    "    overwrite=True,\n",
    ")\n",
    "filled = sum(1 for f in FRAMES_PADDED.iterdir() if f.is_file())\n",
    "print(\"Padded frames dir:\", FRAMES_PADDED)\n",
    "print(\"Total frames after padding:\", filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video path: /app/data/drought_notebook/drought_animation.mp4\n"
     ]
    }
   ],
   "source": [
    "# Compose MP4 animation from padded frames (requires ffmpeg on PATH)\n",
    "video_path = sess.visualize.compose_video(\n",
    "    frames=str(FRAMES_PADDED),\n",
    "    output=str(VIDEO_OUT),\n",
    "    fps=4,\n",
    "    basemap=BASEMAP_REF,\n",
    ")\n",
    "print(\"Video path:\", video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "disseminate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy: /app/data/drought_notebook/drought_animation.mp4\n"
     ]
    }
   ],
   "source": [
    "# Save final animation locally (mirrors disseminate/local stage)\n",
    "final_path = sess.disseminate.local(\n",
    "    input=str(VIDEO_OUT),\n",
    "    path=str(VIDEO_OUT),\n",
    ")\n",
    "print(\"Local copy:\", final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narration: The NOAA drought animation includes padded frames for weeks January 9, 2025, and May 22, 2025.\n"
     ]
    }
   ],
   "source": [
    "# Optional narration of the drought animation\n",
    "narration_meta = summary if isinstance(summary, dict) else {}\n",
    "missing_dates = [\n",
    "    str(ts).split(\"T\")[0] for ts in narration_meta.get(\"missing_timestamps\") or []\n",
    "]\n",
    "missing_dates_str = \", \".join(missing_dates) if missing_dates else \"none\"\n",
    "narration_input = {\n",
    "    \"title\": \"Weekly drought risk animation\",\n",
    "    \"description\": f\"Summarize the NOAA drought animation, note where frames were padded, and list the padded weeks: {missing_dates_str}.\",\n",
    "    \"data\": {\n",
    "        \"frame_count_expected\": narration_meta.get(\"frame_count_expected\"),\n",
    "        \"frame_count_actual\": narration_meta.get(\"frame_count_actual\"),\n",
    "        \"missing_count\": narration_meta.get(\"missing_count\"),\n",
    "        \"missing_timestamps\": narration_meta.get(\"missing_timestamps\") or [],\n",
    "        \"frame_count_after_padding\": filled,\n",
    "        \"padded_weeks\": missing_dates,\n",
    "    },\n",
    "}\n",
    "try:\n",
    "    narration = sess.narrate.swarm(\n",
    "        provider=LLM_PROVIDER,\n",
    "        model=LLM_MODEL,\n",
    "        base_url=os.environ.get(\"OLLAMA_BASE_URL\"),\n",
    "        preset=\"scientific_lite\",\n",
    "        input_data=narration_input,\n",
    "    )\n",
    "    print(\"Narration:\", narration)\n",
    "except Exception as exc:\n",
    "    print(\"Narrate/swarm not executed:\", exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved to /app/data/drought_notebook/drought_pipeline.json\n",
      "CLI commands:\n",
      "zyra acquire ftp --path ftp://ftp.nnvl.noaa.gov/SOS/DroughtRisk_Weekly --sync-dir /app/data/drought_notebook/frames_raw --pattern ^DroughtRisk_Weekly_[0-9]{8}\\.png$ --since-period P1Y --date-format %Y%m%d --workdir /app/data --output /app/data/acquire_ftp.tmp\n",
      "zyra transform scan-frames --frames-dir /app/data/drought_notebook/frames_raw --pattern ^DroughtRisk_Weekly_[0-9]{8}\\.png$ --datetime-format %Y%m%d --period-seconds 604800 --output /app/data/drought_notebook/frames_meta.json --workdir /app/data\n",
      "zyra process pad-missing --frames-meta /app/data/drought_notebook/frames_meta.json --output-dir /app/data/drought_notebook/frames_padded --fill-mode basemap --basemap pkg:zyra.assets/images/earth_vegetation.jpg --overwrite --workdir /app/data\n",
      "zyra visualize compose-video --frames /app/data/drought_notebook/frames_padded --output /app/data/drought_notebook/drought_animation.mp4 --fps 4 --basemap pkg:zyra.assets/images/earth_vegetation.jpg --workdir /app/data\n",
      "zyra disseminate local --input /app/data/drought_notebook/drought_animation.mp4 --path /app/data/drought_notebook/drought_animation.mp4 --workdir /app/data\n",
      "zyra narrate swarm --provider ollama --model gemma3:12b --base-url http://host.docker.internal:11434 --preset scientific_lite --input-data {'title': 'Weekly drought risk animation', 'description': 'Summarize the NOAA drought animation, note where frames were padded, and list the padded weeks: 2025-01-09, 2025-05-22.', 'data': {'frame_count_expected': 51, 'frame_count_actual': 49, 'missing_count': 2, 'missing_timestamps': ['2025-01-09T00:00:00', '2025-05-22T00:00:00'], 'frame_count_after_padding': 51, 'padded_weeks': ['2025-01-09', '2025-05-22']}} --workdir /app/data --swarm-config None --agents None --audiences None --style None --pack None --rubric None --input None --max-workers None --max-rounds None --memory None --guardrails None\n"
     ]
    }
   ],
   "source": [
    "# Export pipeline + CLI equivalents for reproducibility\n",
    "pipeline = sess.to_pipeline()\n",
    "cli_cmds = sess.to_cli()\n",
    "\n",
    "pipeline_path = DROUGHT_DIR / \"drought_pipeline.json\"\n",
    "pipeline_path.write_text(json.dumps(pipeline, indent=2))\n",
    "print(\"Pipeline saved to\", pipeline_path)\n",
    "print(\"CLI commands:\")\n",
    "for cmd in cli_cmds:\n",
    "    print(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zyra-9TtSrW0h-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
